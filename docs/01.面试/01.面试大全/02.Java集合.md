---
title: Java集合
date: 2023-04-08 20:34:26
permalink: /pages/efac31/
---
::: tip
不积跬步无以至千里，内容持续更新中，有问题欢迎大家随时指出
:::
## Java集合框架的基础接口有哪些
Java集合框架中的常用基础接口有Collection、Set、List、Map。其中List和Set接口继承了Collection接口，一个是有序元素集合，一个是无序元素集合；而ArrayList和LinkedList实现了List接口，HashSet实现了Set接口，这几个都比较常用。

**常见**：

- `Collection`：集合接口，继承了 Iterable 接口，代表一组对象的集合。它是 List、Set 和 Queue 接口的父接口，提供了基本的集合操作方法，比如添加、删除、遍历等。
- `List`：有序的 Collection，可以有重复元素。List 接口的实现类有 ArrayList、LinkedList 和 Vector。
- `Set`：不允许有重复元素的 Collection。Set 接口的实现类有 HashSet、LinkedHashSet 和 TreeSet。
- `Map`：一种映射表，由键值对组成。Map 接口的实现类有 HashMap、LinkedHashMap、TreeMap 和 Hashtable。

**其他**：

- `Queue`：队列，继承了 Collection 接口，表示一组按照一定规则排序的元素集合。Queue 接口的实现类有 LinkedList 和 PriorityQueue。
- `Deque`：双端队列，继承了 Queue 接口，可以在队列的两端插入和删除元素，Deque 接口的实现类有 ArrayDeque 和 LinkedList。
- `Iterator`：迭代器接口，用于遍历集合中的元素。Iterator 接口提供了 hasNext()、next() 和 remove() 方法。
- `ListIterator`：List 迭代器，继承了 Iterator 接口，可以双向遍历 List 集合，并可以修改 List 中的元素。
- `SortedSet`：继承了 Set 接口，表示有序的 Set 集合。
- `SortedMap`：继承了 Map 接口，表示有序的 Map 集合。

## Collection 和 Collections 有什么区别
- `Collection`是一个集合接口，它提供了对集合对象进行基本操作的通用接口方法，所有集合都是它的子类，比如List、Set 等。
- `Collections`是一个包装类，包含了很多静态方法，不能被实例化，就像一个工具类，比如提供的排序方法: Collections.sort(list)。

## List、Set、Map是否继承自Collection接口
`List、 Set`是，`Map`不是。
Map是键值对映射容器，与List和Set有明显的区别，而Set存储的零散的元素 且不允许有重复元素，List是线性结构的容器，适用于按数值索引访问元素的情形。

## Collections.sort排序内部原理
在Java 6中Arrays.sort()和Collections.sort()使用的是MergeSort,而在Java 7中，内部实现换成了TimSort，其对对象间比较的实现要求更加严格。

## List、Set、Map 之间的区别
List、Set、Map 都是 Java 集合框架中的接口，它们分别代表了不同的数据结构和操作方式：

- `List`：是一个有序的集合，可以存储重复的元素。List 中的每个元素都有一个与之对应的整数索引，可以通过索引来访问元素。List 通常用于需要按照顺序保存和访问元素的场景。
- `Set`：是一个不允许有重复元素的集合。Set 中的元素没有顺序，即不能按照添加顺序或其他顺序来访问元素。Set 通常用于需要保证元素唯一性的场景。
- `Map`：是一种键值对的集合，每个键最多只能出现一次，而值则可以重复。Map 中的每个元素都由一个键和一个值组成，可以根据键来访问对应的值。Map 通常用于需要根据键来查找值的场景。

除了基本的数据结构和操作方式的不同，List、Set、Map 在 Java 中也有不同的实现类，例如 ArrayList、LinkedList 实现了 `List` 接口，HashSet、TreeSet 实现了 `Set` 接口，HashMap、TreeMap 实现了 `Map` 接口。这些不同的实现类在性能、线程安全等方面也有所不同，开发者可以根据具体的业务需求选择适合的实现类。

## HashMap 和 Hashtable 有什么区别
HashMap和Hashtable都是实现了Map接口的键值对存储结构，它们的主要区别有以下几点：

- `线程安全性`：Hashtable是线程安全的，而HashMap不是线程安全的。也就是说，在多线程环境下，Hashtable可以直接使用，而HashMap需要进行额外的同步操作，否则可能会出现数据不一致等问题。
- `初始容量和容量增长方式`：Hashtable的初始容量为11，而HashMap的初始容量为16。Hashtable的容量增长方式是原容量的2倍加1，而HashMap的容量增长方式是原容量的2倍。
- `对Null值的处理`：Hashtable不允许键或值为null，否则会抛出NullPointerException异常。而HashMap允许键和值为null。
- `迭代器`：Hashtable的迭代器是通过枚举实现的，而HashMap的迭代器是通过Iterator(fail-fast迭代器)实现的。HashMap的迭代器效率要比Hashtable的高。

对于大多数情况下，应该优先使用HashMap。但是，如果需要在多线程环境下进行操作，或者需要使用早期版本的Java，那么Hashtable是更好的选择。

## 如何决定使用 HashMap 还是 TreeMap
对于在Map中`插入、删除、定位`一个元素这类操作，`HashMap`是最好的选择，因为相对而言HashMap的插入会更快，但如果你要对一一个key集合进行`有序`的遍历，那`TreeMap`是更好的选择。

## HashMap 的实现原理
`HashMap` 是 Java 集合框架中的一个实现类，实现了 Map 接口。它是基于哈希表的数据结构实现的，可以提供高效的键值对存储和检索。

具体来说，HashMap 是由一个数组和链表组成的。数组的每个元素是一个链表头，链表中的每个节点存储一个键值对，其中的键和值都是 Object 类型。

HashMap 的核心思想是利用哈希算法，将键映射到数组中的某个索引位置，然后将键值对存储在对应索引位置的链表中。当需要检索某个键对应的值时，通过哈希算法计算出键的索引位置，然后在对应索引位置的链表中查找对应的值即可。

具体的`实现步骤`如下：

1. 创建一个数组，数组的长度是 `2 的幂次方`，这是为了能够利用`位运算`实现更快速的哈希算法。
2. 通过哈希算法计算出键的`哈希值`，然后通过位运算将哈希值转换为数组的`索引位置`。
3. 如果索引位置还没有链表头节点，就创建一个新的节点作为链表头，并将键值对存储在该节点中。
4. 如果索引位置已经存在链表头节点，就遍历该链表，查找键是否已经存在。如果键已经存在，就更新对应节点的值；否则，就创建一个新的节点，将键值对添加到链表的末尾。
5. 如果链表的长度超过了一定阈值（默认是 8），就将链表转换为`红黑树`，从而提高检索效率。
6. 如果哈希表中的元素个数超过了负载因子（默认是 0.75），就将哈希表的大小`扩大一倍`，并`重新计算`每个键的索引位置。
7. 如果数组的大小已经达到了 HashMap 的最大容量（默认是 `2 的 30 次方`），就不再扩容，而是直接抛出 `OutOfMemoryError` 异常。

需要注意的是，由于哈希冲突的存在，即不同的键可能会映射到同一个索引位置，所以在遍历链表或红黑树时需要同时比较键的值，而不能只比较哈希值。为了尽量减少哈希冲突，我们需要合理选择哈希函数、扩容因子等参数，并避免使用不适合哈希算法的数据类型作为键。

## HashSet 的实现原理
HashSet是一种基于HashMap实现的集合类，它继承了AbstractSet类，实现了Set接口。HashSet底层使用HashMap来存储集合元素，具体实现方式如下：

- 创建一个初始容量为16，加载因子为0.75的HashMap对象。
- 将元素添加到HashMap中，其中元素作为key，Object类型的常量对象作为value。
- 添加元素时，先调用元素的hashCode()方法得到元素的哈希值，然后使用哈希值计算出元素应该存储在HashMap的哪个桶（bucket）中。
- 如果桶中没有元素，则将元素放入桶中；如果桶中已经有元素，则将元素与桶中的所有元素进行比较，如果存在相同的元素，则不将元素放入桶中，如果不存在相同的元素，则将元素放入桶中。
- 当HashMap中的元素个数超过了负载因子乘以容量时，HashMap会自动进行扩容，扩容后容量将变为原来的两倍，并将原来的元素重新散列到新的桶中。

HashSet的实现原理就是基于HashMap实现的，所以它具有与HashMap相同的特点，比如说：

- HashSet中的元素是无序的。
- HashSet中不允许存储重复元素，如果添加重复元素，则只会保留一个元素。
- HashSet中可以存储null元素。
- HashSet的性能与元素数量和负载因子有关，负载因子越小，HashSet的性能越高，但是会占用更多的空间。

## ArrayList 和 LinkedList 的区别
ArrayList和LinkedList是Java集合框架中的两种List实现。它们的主要区别在于底层的数据结构和性能表现方面。

- `数据结构`：ArrayList底层使用的是`数组`，而LinkedList底层使用的是`双向链表`。
- `随机访问性能`：由于ArrayList底层是数组结构，因此支持随机访问，即可以通过下标访问元素。时间复杂度为O(1)。而LinkedList不支持随机访问，访问元素需要从头节点开始遍历，时间复杂度为O(n)。
- `插入、删除操作性能`：ArrayList在末尾进行插入、删除操作的时间复杂度为O(1)，而在中间或开头进行插入、删除操作时，需要将插入或删除位置之后的元素全部向后或向前移动，时间复杂度为O(n)
  。LinkedList在末尾进行插入、删除操作的时间复杂度为O(1)，而在中间或开头进行插入、删除操作时，只需要改变指针的指向，时间复杂度为O(1)。
- `内存占用`：由于LinkedList底层使用的是双向链表，每个元素需要存储前后指针，因此内存占用比ArrayList大。

综上所述，ArrayList适用于随机访问和末尾插入、删除操作较多的场景，而LinkedList适用于频繁的中间或开头的插入、删除操作。

## 为何Map接口不继承Collection接口
Map 接口是键值对映射（即 key-value 映射），而 Collection 接口提供的是一组数据，这两个集合存储的数据类型就不同。如果 Map 继承 Collection，违反了接口分离原则。

- `Collection`接口的目的是表示一组对象，通常用于表示一个列表或集合，提供一系列操作集合元素的方法，比如添加元素、删除元素、遍历集合等。
- `Map`接口的目的是表示一组键值对，通常用于表示一个映射关系，提供一系列根据键获取值的方法，比如put(key, value)、get(key)、containsKey(key)
等。因此，Map接口的实现类要求元素必须成对出现，即每个key都对应一个value。

由于这两个接口的设计目的和操作方式不同，因此Map接口不继承Collection接口，但它们都属于Java集合框架的一部分。

## ArrayList和Vector有何异同点
ArrayList和Vector在很多时候都很类似。
- (1)两者都是基于索引的，内部由一个数组支持。
- (2)两者维护插入的顺序，我们可以根据插入顺序来获取元素。
- (3) ArrayList和Vector的迭代器实现都是fail-fast的。
- (4) ArrayList和Vector两者允许null值，也可以使用索引值对元素进行随机访问。

以下是ArrayList和Vector的不同点。

- (1) Vector是同步的，而ArrayList不是。然而，如果你寻求在迭代的时候对列表进行改变，你应该使用CopyOnWriteArrayList。
- (2) ArrayList是不同步的，而Vector是同步的，所以ArrayList更高效，不会过载
- (3) ArrayList更加通用，因为我们可以使用Collections工具类轻易地获取同步列表和只读列表。

## Array 和 ArrayList 有何区别
Array和ArrayList是两种不同的数据结构。
- `Array`是Java中的基本数据类型之一，表示一组相同类型的元素的连续集合。它的长度是固定的，一旦被创建就无法改变。
- `ArrayList`是Java中的集合类之一，是基于数组实现的动态数组，其大小可以根据需要进行动态调整。ArrayList可以存储任何类型的对象，而不仅仅是基本数据类型。

下面是Array和ArrayList的主要区别：

| 区别   | Array                | ArrayList                                    |
|------|----------------------|----------------------------------------------|
|长度| 	长度固定，一旦创建就无法改变      | 	长度可变，根据需要动态调整                               |
|元素类型| 	可以存储基本数据类型或对象类型     | 	只能存储对象                                      |
|遍历| 	可以使用for循环或增强for循环遍历 | 	可以使用for循环、增强for循环、迭代器遍历                     |
|添加/删除元素| 	需要手动移动元素，效率较低       | 	可以使用内置的方法进行添加/删除操作，效率较高                     |
|线程安全| 	非线程安全               | 	非线程安全，可以使用Collections.synchronizedList()方法使其线程安全 |

总之，Array适合存储数量固定的基本数据类型或对象类型的元素，而ArrayList适合存储数量可变的对象元素，并且提供了更方便的添加、删除和遍历操作。
下面是 Java 代码示例：

```java
// 创建一个数组
int[] arr = new int[5];

// 创建一个 ArrayList
ArrayList<Integer> arrayList = new ArrayList<Integer>();
```

## 在 Queue 中 poll()和 remove()有什么区别
在 Queue 接口中，poll() 和 remove() 都是用于获取队列头部元素并将其从队列中移除的方法，但是它们在队列为空时的表现不同。

如果队列为空，调用 poll() 方法会返回 null，而不会抛出异常。例如：

``` java
Queue<String> queue = new LinkedList<>();
String element = queue.poll(); // element 将会是 null
```

相反，如果队列为空，调用 remove() 方法会抛出 NoSuchElementException 异常。例如：

``` java
Queue<String> queue = new LinkedList<>();
String element = queue.remove(); // 抛出 NoSuchElementException 异常
```

因此，在对队列进行操作时，如果不确定队列是否为空，最好使用 poll() 方法，并检查其返回值是否为 null，以避免抛出异常。

**拓展**：
- 压入元素(添加)：add()、offer()
  - 相同：未超出容量，从队尾压入元素，返回压入的那个元素。
  - 区别：在超出容量时，add()方法会对抛出异常，offer()返回false

- 弹出元素(删除)：remove()、poll()
  - 相同：容量大于0的时候，删除并返回队头被删除的那个元素。
  - 区别：在容量为0的时候，remove()会抛出异常，poll()返回false

- 获取队头元素(不删除)：element()、peek()
  - 相同：容量大于0的时候，都返回队头元素。但是不删除。
  - 区别：容量为0的时候，element()会抛出异常，peek()返回null。

## LinkedHashMap有什么特点
LinkedHashMapHashMap的一个子类，保存了记录的插入顺序，在用Iterator遍历LinkedHashMap
时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。

## HashMap的底层实现原理
从结构实现来讲，HashMap是数组+链表+红黑树(JDK1.8增加 了红黑树部分)实现的，如下如所示。
![image](https://cdn.staticaly.com/gh/1292401015/picx-images-hosting@master/20230409/image.471apc4qgys0.webp)

**(1)**、从源码可知，HashMap类中有一一个非常重要的字段，就是`Node[] table`, 即哈希桶数组，明显它是一个`Node的数组`。Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射
(键值对)。上图中的每个黑色圆点就是一个Node对象。 我们来看Node`JDK1.8`源码。
``` java
public class HashMap<K,V> extends AbstractMap<K,V>
    implements Map<K,V>, Cloneable, Serializable {
    /**
     * The table, initialized on first use, and resized as
     * necessary. When allocated, length is always a power of two.
     * (We also tolerate length zero in some operations to allow
     * bootstrapping mechanics that are currently not needed.)
     * 该表在第一次使用时初始化，并根据需要调整大小。在分配时，长度总是2的幂。
     * (我们还允许某些操作的长度为0，以允许目前不需要的引导机制
     */
    transient Node<K,V>[] table;// 桶数组
    
    static class Node<K,V> implements Map.Entry<K,V> {
        final int hash; //⽤用来定位数组索引位置
        final K key;
        V value;
        Node<K,V> next; //链表的下⼀一个node
        Node(int hash, K key, V value, Node<K,V> next) { … }
        public final K getKey(){ … }
        public final V getValue() { … }
        public final String toString() { … }
        public final int hashCode() { … }
        public final V setValue(V newValue) { … }
        public final boolean equals(Object o) { … }
    }
}

```

**(2)**、HashMap就是使用哈希表来存储的。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题，Java中HashMap采用了链地址法。Java8中链表长度超过8时会自动转换为红黑树

链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被Hash后，得到数组下标，把数据放在对应下标元素的链表上。

**(3)**、HashMap的内部功能实现很多，本文主要从根据key获取哈希桶数组索引位置、put方 法的详细执行、 扩容过程三个具有代表性的点深入展开讲解。
### 1.确定哈希桶数组索引位置
不管增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步。前面说过HashMap的数据结构是数组和链表的结合，所以我们当然希望这个HashMap里面的元素位置尽量分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，不用遍历链表，大大优化了查询的效率。HashMap定位数组索引位
置，直接决定了hash方法的离散性能。先看看源码的实现(方法一+方法二):
``` java
⽅方法⼀：
static final int hash(Object key) { //jdk1.8 & jdk1.7
  int h;
  // h = key.hashCode() 为第⼀一步 取hashCode值
  // h ^ (h >>> 16) 为第⼆二步 ⾼高位参与运算
  return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
⽅方法⼆：
static int indexFor(int h, int length) { //jdk1.7的源码，jdk1.8没有这个⽅方法，但
  是实现原理理⼀一样的
  return h & (length-1); //第三步 取模运算
}
```

这里的Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算。

对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算 
得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。

这个方法非常巧妙，它通过h & (table.length -1)来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。当length总 是2的n次方时，h& (length-1)运算等价于对length取模，也就是h%length,但是&比%具有更高的效率。在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的 高16位异或低16位实现的: (h=k.hashCode()^ (h>>>16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。

下面举例说明下，n为table的长度。
![image](https://cdn.staticaly.com/gh/1292401015/picx-images-hosting@master/20230409/image.22a04jycde1s.webp)

### 2.HashMap的put方法
HashMap的put方法执行过程可以通过下图来理解，自己有兴趣可以去对比源码更清楚地研究学习。

![image](https://cdn.staticaly.com/gh/1292401015/picx-images-hosting@master/20230409/image.4yahoi5joe40.webp)

①.判断键值对数组table[i]是否为空或为null,否则执行resize()进行扩 容;

②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null,直接新建节点添加，转向⑥，如
果table[i]不为空，转向③;

③判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是
hashCode以及equals;

④.判断table[i]是否为treeNode,即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，
否则转向⑤;

⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作,
否则进行链表的插入操作;遍历过程中若发现key已经存在直接覆盖value即可;

⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold,如果超过，进行扩容。

JDK1.8HashMap的put方法源码如下: 
``` java
public V put(K key, V value) {
    // 先对key的hashCode()做hash
    return putVal(hash(key), key, value, false, true);
}
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
/**
 * Implements Map.put and related methods
 *
 * @param hash hash for key
 * @param key the key
 * @param value the value to put
 * @param onlyIfAbsent if true, don't change existing value
 * @param evict if false, the table is in creation mode.
 * @return previous value, or null if none
 */
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    // 步骤①：tab为空则创建
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    // 步骤②：计算index，并对null做处理
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    else {
        Node<K,V> e; K k;
        // 步骤③：节点key存在，直接覆盖value
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        // 步骤④：判断该链为红黑树
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            
        // 步骤⑤：该链为链表
        else {
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    //链表⻓长度⼤大于8转换为红黑树进行处理
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                // key已经存在直接覆盖value
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        if (e != null) { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    // 步骤⑥：超过最⼤大容量量 就扩容
    if (++size > threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
```
### 3.扩容机制
扩容(resize)就是重新计算容量，HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。
我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些， 本质上区别不大，具体区别后文再说。
``` java
void resize(int newCapacity) { //传⼊入新的容量量
  Entry[] oldTable = table; //引⽤用扩容前的Entry数组
  int oldCapacity = oldTable.length;
  
  if (oldCapacity == MAXIMUM_CAPACITY) { //扩容前的数组⼤大⼩小如果已经达到最⼤大(2^30)了了
    threshold = Integer.MAX_VALUE; //修改阈值为int的最⼤大值(2^31-1)，这样以后就不不会扩容了了
    return;
  }

  Entry[] newTable = new Entry[newCapacity]; //初始化⼀一个新的Entry数组
  transfer(newTable); //！！将数据转移到新的Entry数组里
  table = newTable; //HashMap的table属性引⽤用新的Entry数组
  threshold = (int)(newCapacity * loadFactor);//修改阈值
}
```
这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方 法将原有Entry数组的元素拷贝到新的Entry数组里。
``` java
void transfer(Entry[] newTable) {
    Entry[] src = table; //src引⽤用了了旧的Entry数组
    int newCapacity = newTable.length;
    
    for (int j = 0; j < src.length; j++) { //遍历旧的Entry数组
        Entry<K,V> e = src[j]; //取得旧Entry数组的每个元素
        if (e != null) {
            src[j] = null;//释放旧Entry数组的对象引⽤用（for循环后，旧的Entry数组不再引⽤用任何对象）
            do {
              Entry<K,V> next = e.next;
              int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置
              e.next = newTable[i]; //标记[1]
              newTable[i] = e; //将元素放在数组上
              e = next; //访问下⼀一个Entry链上的元素
            } while (e != null);
        }
    }
}
```

newTable[i]的引用赋给了e.next,也就是使用了单链表的`头插入`方式，同一位置上新元素总会被放在链表的头部位置;这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话)，这一点和Jdk1.8有区别，下文详解。在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。

**下面举个例子说明下扩容过程。**

假设了我们的hash算法就是简单的用key mod一下表的大小(也就是数 组的长度)。其中的哈希桶数组table的size=2，所以key=3、 7、5，put顺序依次为5、7、3。在mod2以后都冲突在table[1]这里了。这里假设负载因子loadFactor=1，即当键值对的实际大小size大于table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组resize成4，然后所有的Node重新rehash的过程。

![image](https://cdn.staticaly.com/gh/1292401015/picx-images-hosting@master/20230409/image.4neeo2oygk80.webp)

下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。看下图可以明白这句话的意思，n为table的长度，图(a) 表示扩容前的key1和key2两种key确定索引位置的示例，图(b) 表示扩容后key1和key2两种key确定索引位置的示例，其中hash1 是key1对应的哈希与高位运算结果。

![image](https://cdn.staticaly.com/gh/1292401015/picx-images-hosting@master/20230409/image.70jvxy8k4mo0.webp)

元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化:

![image](https://cdn.staticaly.com/gh/1292401015/picx-images-hosting@master/20230409/image.2huno6ua7h40.webp)

因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash,只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成‘原索引+oldCap"，可以看看下图为16扩充为32的resize示意图:

![image](https://cdn.staticaly.com/gh/1292401015/picx-images-hosting@master/20230409/image.lf6pvjom94g.webp)

这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1 可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别， JDK1.7中rehash的时候， 旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可
以研究下JDK1 8的resize源码，写的很赞，如下:
``` java
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) {
        // 超过最大值就不不再扩充了，就只好随你碰撞去吧
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        // 没超过最大值，就扩充为原来的2倍
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    else {               // zero initial threshold signifies using defaults
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    // 计算新的resize上限
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    @SuppressWarnings({"rawtypes","unchecked"})
        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    if (oldTab != null) {
        // 把每个bucket都移动到新的buckets中
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order 链表优化重hash的代码块
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        // 原索引
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        // 原索引+oldCap
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    
                    // 原索引放到bucket里
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    // 原索引+oldCap放到bucket⾥里
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
```

## HashMap并发安全的问题
HashMap 是线程不安全的，在并发环境下会出现脏读脏写的问题。在 JDK1.7 版本的 HashMap 中甚至会出现著名的环形链表的问题，不过环形链表在 JDK1.8 中由于将头插法改为尾插法而被解决了。

如果需要在多线程环境下使用 HashMap，可以使用 ConcurrentHashMap 来代替 HashMap。ConcurrentHashMap 是线程安全的，它是通过分段锁来实现的。

## HashMap 1.7死循环案例（环形链表）
并发的多线程使用场景中使用HashMap可能造成死循环。代码例子如下(便于理解，仍然使用DK1.7的环境):
``` java
public class HashMapInfiniteLoop {
    private static HashMap<Integer,String> map = new HashMap<Integer,String>(2，0.75f);
    public static void main(String[] args) {
        map.put(5， "C");
        // 线程1
        new Thread("Thread1") {
            public void run() {
                map.put(7, "B");
                System.out.println(map);
            };
        }.start();
        // 线程2
        new Thread("Thread2") {
            public void run() {
                map.put(3, "A);
                System.out.println(map);
            };
        }.start();
    }
}
```

其中，map初始化为一个长度为2的数组，loadFactor=0.75， threshold=2*0.75=1, 
也就是说当put第二个key的时候，map就需要进行resize。通过设置断点让线程1和线程2同时debug到transfer方法(扩容机制小节有代码)
的首行。注意此时两个线程已经成功添加数据。放开thread1的断点至transfer方法的“Entry next= e.next;"这一行;然后放开线程2的的断点，让线程2进行resize。结果如下图。
![image](https://cdn.staticaly.com/gh/1292401015/picx-images-hosting@master/20230409/image.5juhhscbas80.webp)

注意，Thread1的 e指向了key(3),而next指向了key(7),其在线程二rehash后，指向了线程二重组后的链表。

线程一被调度回来执行，先是执行newTalbe[i]=e，然后是e= next,导致了e指向了key(7)，而下一次循环的next = e.next导致了next指向了key(3)。
![image](https://cdn.staticaly.com/gh/1292401015/picx-images-hosting@master/20230409/image.53o2khgz2qw0.webp)

e.next = new Table[i]导致key(3).next指向了key(7)。注意:此时的key(7).next 已经指向了key(3)，环形链表就这样出现了。
![image](https://cdn.staticaly.com/gh/1292401015/picx-images-hosting@master/20230409/image.3fc912brqui0.webp)

于是，当我们用线程一调用map.get(11)时，悲剧就出现了 一 Infinite Loop。

## JDK1.8与JDK1.7的性能对比
HashMap中，如果key经过hash算法得出的数组索引位置全部不相同，即Hash算法非常好， 那样的话，getKey方法的时间复杂度就是O(1)
，如果Hash算法技术的结果碰撞非常多，假如Hash算极其差，所有的Hash算法结果得出的索引位置一样，那样所有的键值对都集中到一个桶中，或者在一个链表中，或者在一个红黑树中，时间复杂度分别为O(n)和O(lgn)。鉴于JDK1.8做了多方面的优化，总体性能优于JDK1.7。

## HashMap操作注意事项以及优化
- (1) 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化时候给一个大致的数值，避免map进行频繁的扩容。
- (2) 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。
- (3) HashMap是线程不安全的，不要在并发的环境中同时操作HashMap,建议使用ConcurrentHashMap.
- (4) JDK1.8引入红黑树大程度优化了HashMap的性能。
- (5) JDK1.8的HashMap的性能提升很多，应尽可能使用1.8以上版本。


参考资料：https://space.bilibili.com/1814002734